# GPU-optimized Dockerfile using NVIDIA CUDA base image
# For GPU acceleration, use this file instead of the regular Dockerfile
# Build: docker build -f Dockerfile.gpu -t insightface-gpu .

# Stage 1: Build stage with CUDA support
FROM nvidia/cuda:12.6.0-cudnn-runtime-ubuntu22.04 as builder

# Install Python 3.11
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    libpq-dev \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Upgrade pip
RUN python -m pip install --upgrade pip setuptools wheel

WORKDIR /app

# Copy requirements and create GPU-specific requirements
COPY requirements.txt requirements-base.txt

# Replace onnxruntime with onnxruntime-gpu for CUDA acceleration
RUN sed 's/onnxruntime>=/onnxruntime-gpu>=/' requirements-base.txt > requirements.txt

# Install dependencies
RUN pip install --no-cache-dir --prefix=/install -r requirements.txt

# Stage 2: Runtime stage with CUDA
FROM nvidia/cuda:12.6.0-cudnn-runtime-ubuntu22.04

# Install Python and runtime dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3-pip \
    libpq5 \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

WORKDIR /app

# Copy installed packages from builder
COPY --from=builder /install /usr/local

# Copy application code
COPY app/ ./app/

# Set environment variables
ENV PYTHONPATH=/app \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    CUDA_VISIBLE_DEVICES=0

# Add healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:5555/health', timeout=5)" || exit 1

# Start API with optimized settings for GPU
# Single worker since GPU memory is shared
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "5555", "--workers", "1", "--timeout-keep-alive", "75"]
